 # 사이킷런
## 교차검증

1. KFold
    - KFold 란? 
        * 세트 개수를 설정하면 해당 개수로 학습_데이터, 테스트_데이터 로 나눠서 학습과 테스트를 진행한다.
    - KFold 문제점
        * 학습_데이터와 테스트_데이터 의 세트에 타겟 값이 골고루 분포하지 않을 경우가 발생할 수 있다
        * 예를 들어, 3가지 타겟(0,1,2)이 있는 데이터를 3 세트로 나눌 경우 학습 데이터에 타겟 2 가 포함 되지 않으면 2를 예측 할 수 없다.
    - 사용 예)
    ~~~python
        # kfold 선언 및 세트 개수 설정
        kfold = KFold(n_split=3)
        # 교차 검증 진행
        for train_idx, test_idx in kfold.split(features) : 
            # 학습 데이터, 테스트 데이터 추출
            # 데이터
            X_train, X_test = features[train_index], features[test_index]
            # 타겟(=라벨)
            Y_train, Y_test = label[train_index], label[test_index]

            # 학습
            ${검증알고리즘}.fit(X_train, Y_train)
            # 예측
            pred = ${검증알고리즘}.predict(X_test)
            # 정확도 측정
            acc = accuracy_score(y_test,pred)
    ~~~

2. StratifiedKFold
    - StratifiedKFold 란?
        * 데이터의 세트 분할 시 타겟(=라벨)의 속성값의 개수를 동일하게 나눠 세트를 구성한다.
        * 따라서 학습 데이터 세트와 테스트 데이터 세트에 라벨이 몰리거나 누락되는 경우를 방지한다.
    - 사용 예)
    ~~~ python
        # StratifiedKFold 선언 및 세트 개수 설정
        skfold = StratifiedKFold(n_split=3)
        # KFold 와 달리 교차 검증 진행에 features와 label을 같이 넣어준다.
        # label 에 따라 세트를 나누기 때문에
        for train_idx, test_idx in skfold.split(features, label) : 
            # 학습 데이터, 테스트 데이터 추출
            # 데이터
            X_train, X_test = features[train_index], features[test_index]
            # 타겟(=라벨)
            Y_train, Y_test = label[train_index], label[test_index]

            # 학습
            ${검증알고리즘}.fit(X_train, Y_train)
            # 예측
            pred = ${검증알고리즘}.predict(X_test)
            # 정확도 측정
            acc = accuracy_score(y_test,pred)
    ~~~
3. cross_val_score()
    - cross_val_score 이란?
        * 세트의 추출, 학습/예측, 평가를 한번에 수행 할 수 있게 해주는 함수
    ~~~ python
        scores = cross_val_score(estimator, DATA, LABEL, scoring="accuracy(= 정확도)", cv=${폴드 수})
    ~~~ 
4. GridSearchCV
    - GridSearchCV 란?
        * 하이퍼 파라미터(= 튜닝 파라미터) 를 순차적으로 입력하면서 최적의 파라미터 값을 도출하는 방안 제공
    - 생성자 주요 파라미터
        * estimator : classifier, regressor, pipeline이 사용될 수 있다.
        * param_grid : 파라미터 딕셔너리. (파라미터명과 사용될 여러 파라미터 값을 지정)
        * scoring : 예측 성능을 측정할 평가 방법. 보통은 사이킷런에서 제공하는 문자열 (예: ‘accuracy’)을 넣지만 별도의 함수도 직접 지정이 가능하다.
        * cv : 교차 검증을 위해 분할되는 폴드 수.
        * refit : True면 가장 최적의 하이퍼 파라미터를 찾은 뒤 입력된 estimator 객체를 해당 하이퍼 파라미터로 재학습시킨다. (default:True)
    ~~~ python
        # 파라미터는 반드시 리스트 형태여야 한다.
        parameters = {"max_depth":[1,2,3] , "min_sample_split":[2,3]}
        # refit = true : 최적의 하이퍼 파라미터를 찾게 되면 검증 알고리즘을 학습 시킴
        gridCV =  GridSearchCV(estimator, param_grid=parameters, cv=${폴드 수}, refit=True)
    ~~~
